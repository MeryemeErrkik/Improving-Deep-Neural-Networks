{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import sys\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "((Xtrain_o, Ytrain_o), (Xtest_o, Ytest_o)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain_o.shape)\n",
    "print(Xtest_o.shape)\n",
    "print(Ytrain_o.shape)\n",
    "print(Ytest_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=Xtrain_o.reshape(Xtrain_o.shape[0],28*28)\n",
    "X_test=Xtest_o.reshape(Xtest_o.shape[0],28*28)\n",
    "Y_train=Ytrain_o\n",
    "Y_test=Ytest_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=(X_train-X_train.mean())/255\n",
    "X_test= (X_test-X_test.mean())/255\n",
    "Y_train = to_categorical(Y_train,10)\n",
    "Y_test = to_categorical(Y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "Y_train=Y_train.T\n",
    "Y_test=Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(784, 10000)\n",
      "(10, 60000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a picture of a(n) Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN30lEQVR4nO2dbYycVRXH/2dm562zu93tbrst2y3b0heKTQuklGL5gBqkgAkhRnlJjFGSGqOJGj8IKiYmGjEx+smQECTYRDEEEEjAoBKlGktpVaAtte3S16Uvu9t233dn5+X6YYed+Z92Z6d3d97a80uanf/zzD7Pne2Ze89z7rnninMOhnG5BCrdAKM2McMxvDDDMbwwwzG8MMMxvDDDMbyYleGIyFYROSgiXSLy6Fw1yqh+xDeOIyJBAIcA3AmgG8BuAA855z6Yu+YZ1UrdLH53E4Au59wRABCRPwC4D8C0hhOWiIsiPotbXgaitPp+SCRMOrEgRDpyLkk6E5v+TxUYS/GtJiZIp1v4M6cj/PvhUyPTXrvSDOFCn3NuoT4+G8NpB3AyT3cDuLXQL0QRx63yGf87Sp416J5S2FIkGCTtUvyfG1y2nPTRh5eQXrG9m/TIJ9r4fnm3j39wlk6ljp0g3X/vbaxX86U6H9/JB9Rnueizai73/ZfBX90Lxy91fDaGo7/TwEXfa0BEtgHYBgBRzJvF7YxqYjbOcTeAjjy9FMAp/Sbn3FPOuY3OuY0hRPRpo0aZTY+zG8AqEVkO4CMADwJ4eE5aNR35XfAM3bMemjQrnmMbvznURTr4+Qzp5w/NJ71swYWp18cH+Fy4bg3pxQ3c2z+2dAfpJx9fyY273KGmAhPV3objnEuJyDcBvAEgCOAZ59z+OWuZUdXMpseBc+51AK/PUVuMGsIix4YXs+pxyk4g7xE7ky741tH7OTIw8pV+0usCh0knHT++HxpeRHrNoh7SRy4smHrdWs9xmEiQ/atkhq/9fM8tpHtf5Xst+jH/t7h/Kw8gwNeDyyhdep/HehzDCzMcwwszHMOL2vJx9Fiex5Gfc1h/271/Jv3fgWWkd/V2kl4cHyS9dB77RJ9sYJ9oV/11U68fWLCLzj159tOkjw62kD4x1Ex6dUsv6RVP95F+81dbSDdt5ykKiXBg1SUSKDXW4xhemOEYXpjhGF7Ulo9TgLWbj5I+OsYpJIPJKOlIHcdaDvRw2sS1nedJv9x7M+ldRzunXres5zjO2yc7SccinJ/TGGUf5MxII+lUhr/Po/cPkG7aTvJin6ZQ+skcYT2O4YUZjuFFbQ1Ved1uYP31dKoxdIb0+QlOGlvTwFl6b6vHcZ2lMZiKkR5P858qM5rTCcfngkEOG0RCPCzqoSiRUtd2DaRb4qN8/ZWcvZju4mE6P/txpvQSX6zHMbwwwzG8MMMxvKgtHyeP8zdy2L7ZsQ9zapjTObc0fUh6R0qlayoG1ON7VKVKIJDzt8YzvLRmJgbG+No6LWNwnKcQmmLjpC9suoZ0o/JxXLpwyslcYD2O4YUZjuGFGY7hRc36OAPKRdFTCvVhDsM3BMdIN0bZbxgeY78iXsfTBDr9M1SfOz8vwO8NBDiOMzjKbUtO8J+9P8Axo7TjoFIyzfc+u5mnERp/D8ZSR41qxQzH8MIMx/CiZn2cRDuXIQkHOM7SEuH5nQmn54PYj2iq5/cPTLBfcnKQ40ahUC5WsqOXHS49t3RuhOfNInH2r5rnsf/Vr+I8STW3tW4DLykufaLoxViPY3hhhmN4YYZjeFGzPk5rGy9n+WwrV5BbEVZLdid4me2Eio2EVOxlJMlxHR33yWdwvHBaqp5r0v7Vwtgw6dEkz33pONDXlv+D9HPguatyYD2O4cWMhiMiz4hIj4jsyzu2QET+IiKHsz+bC13DuPIopsd5FsBWdexRAG8651YBeDOrjauIGX0c59wOEelUh+8DcEf29W8B/B3A9+awXTOypIF9nM2xI6TTqrblexn2E8JBzlnRPs/8CMdWhpXPEw/z/FQhRHjuKKlyjHUO8k9Wv8z6yOdIv3z2Jr7BJvbf8M7eotvmi6+P0+acOw0A2Z+LZni/cYVR8qcqK1d7ZeLb45wVkSUAkP3ZM90brVztlYlvj/MqgC8DeCL785U5a1GR6DIk5zLcmx2b4CXAHwxzrCOg/A4dxxlPcyzlUwsPku4azY3O/+npoHN1yn9qVLlBE8L+1JCaF0uqebUH2veQ7kvxuqvX1DqrxndQcop5HH8OwE4Aa0SkW0QewaTB3CkihzG5CcgTpW2mUW0U81T10DSnZrEpg1HrWOTY8KJm56p0jrH2CxbWcZxnTPksIxO87VAsxPk9dcJ+yq4L7EcMTOTyhOsj7MOcV/k32sfRTKh85sVBbvsfh7nESlNI5e+s4u8/F00pDdbjGF6Y4RhemOEYXtSsj9MY4hyXQTUXtSg4RFqvJdfEQ2ptlIrz6LhOfk5Ns8pv1mu/QyquE1bbCQwn+P1rw/x93tSgytQl1E6Hl9pyrsRYj2N4YYZjeFFTQ5WEco/QK2M8PdY1vph0e/0F0voRWZcW0UNTOMDDiS5zcm4sdz09zIXr+Hf7x3mJb2OEh1m9fOZPo5wXdzbJw2w0wKGDZLz8O+RZj2N4YYZjeGGGY3hRUz5OsC33GFof5A3ldTm1pgCH+fUjcVClUej0zViQ/QhNNG8JzFgqNO05AOgdqudr6+kN1Zao8PmjY62kA8LvD3Xy8ppyYD2O4YUZjuGFGY7hRU35OOm2pqnXehmtJqrSIpY3nyM9pNIymsKcqtCbYL/knoW85CQ/7nN6jBMZQgFu2/yLyphwXEeXRdk7vpT0jQ0nSH+U4DhPfaz8hU6sxzG8MMMxvDDDMbyoKR9nZFnO79CposNpTk24LsQ+io6V6K1+uoebSDdF2S/ZPcipoydGcn5GW4xTOD4a4bkl7Y3pGFLfcJx0x1LenW8kw5+tP8VzWx2NPC/Hs3ClwXocwwszHMMLMxzDi9rycdpydj6a4eUtiQx/lITj+Z6BBMdOxlS5tFXNvaS3NHeRfn+YYyuxutz1l8XYJ9ElUeap8v7anxpJ8Gc5mVxA+q76/aQ/HOfiILE4X38fSo/1OIYXZjiGF2Y4hhc15eMkmnMRkbRjm9fbPQ9leNzXpdkyKrrSGuGclr4klxI5l+BYS/4SYR1DumbeAOkAOCc43sRtO1HHc096G6N+tfQnrb7v7REu+bI/kstbconSzGNZj2N4UUx9nA4R+ZuIHBCR/SLyrexxK1l7FVNMj5MC8F3n3FoAmwF8Q0RugJWsvaopprDSaQAfVxgdEpEDANpRBSVr82mLcGmQ3nThfJ38OMyl2D+0hPT1Dbw99enx3HzUSIp9HO0PadpigwXP65xjjY5ZJR2XSQl05krLpQ9yPGquuCwfJ1vv+CYAu2Ala69qijYcEakH8CKAbzvnCn9l+Pe2icgeEdmTrMiWXEYpKMpwRCSESaP5nXPupezhokrWWrnaK5MZfRwREQC/AXDAOffLvFNlL1mbKWB3yyKcU3wyxTkxet2UzlnuUznGem5rZSv7OP8bapu2LbrsSfcIz02F1LooXcpNM5PPoxlY3zL1ur5EPk4xAcAtAL4EYK+IvJs99n1MGszz2fK1JwB8oSQtNKqSYp6q/onpS/dYydqrFIscG17U1FxVOpyb82kIco2Z0xPsR0SlcGm2OuVnDKtYjI7zHBjjkv75PtLCKM9zDSTZP5qv1mydGed5MF1fZ9xxrpAmCG67Xks+1pLrD9hzmzusxzG8MMMxvDDDMbyoKR8n2ZzLgdE5wPE6jkpvjLPfoWv69Y3x6K/r8unYSmuI1071R3N+jI7LxIPssySE/8z9E+wDJdW2jj1JXoveHy68Qdzu/k6+X3Pp69daj2N4YYZjeFFTQ1XHitwSlpXzeGqstY6HkvYgp2/qMibHhwrnnemhrSHAQ1l+mRSddqof/XVZuPEg/9n18plFIZ5DjquydIvC/Fl1WsWZO07nxM9QEqzHMbwwwzG8MMMxvKgpHyd2V24XlbfauOxI+iz7PC+2rSe98jUuBZJWaRbnx/iR95p69pH0zrvrGk5NvT6V4OkOnbKhUz31rr+rGnn58S/eupv06q/ztr6BDWtJw6nlN4eO5dqC0mA9juGFGY7hhRmO4UVN+Tj5aJ9mpvO3N/Iuc11DvMvc2sYzpPWy2g2x46S/s/eLU6+f3rCdzh1Lcgl9HYd5qW8j6XVx3l7gteg6FCLz3oGC58uB9TiGF2Y4hhdmOIYXteXjBAosI1E762p++MLDfCneGQhHU52k1fQPVOURdPz0X1Ovf3TLV+lcKs6pn0PLOC1VbSiMnUs45rRi5wwLF9XfQQLTp1G4VGrac7PBehzDCzMcwwszHMMLca58Ww+LSC+A4wBaAfSV7caXR7W2rVLtutY5t1AfLKvhTN1UZI9zbuPM7yw/1dq2amuXDVWGF2Y4hheVMpynKnTfYqjWtlVVuyri4xi1jw1VhhdlNRwR2SoiB0WkS0QqWt5WRJ4RkR4R2Zd3rCpqN9dCbemyGY6IBAH8GsDdAG4A8FC2XnKleBbAVnWsWmo3V39taedcWf4BuA3AG3n6MQCPlev+07SpE8C+PH0QwJLs6yUADlayfXntegXAndXUvnIOVe0ATubp7uyxaqLqajdXa23pchrOpeb+7ZGuAL61pctBOQ2nG0BHnl4K4NQ0760URdVuLgezqS1dDsppOLsBrBKR5SISBvAgJmslVxMf124GylS7+VIUUVsaqGD7AJTPOc46dPcAOATgQwA/qLDD+RwmNzdJYrI3fARACyafVg5nfy6oUNtux+Qw/j6Ad7P/7qmW9jnnLHJs+GGRY8MLMxzDCzMcwwszHMMLMxzDCzMcwwszHMMLMxzDi/8DHIES1/n/wEUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=np.random.randint(60000, size=1)\n",
    "Y=X_train.T[s]\n",
    "Y_img=np.array(Y)\n",
    "plt.figure(figsize = (10,2))\n",
    "Y_img=Y_img.reshape(28,28)\n",
    "plt.imshow(Y_img)\n",
    "print(\"It's a picture of a(n)\",labels[int(Ytrain_o[s])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I-Simple Neural network:#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://www.researchgate.net/profile/Facundo_Bre/publication/321259051/figure/fig1/AS:614329250496529@1523478915726/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful functions(Sigmoid,ReLU,sigmoid_backward,ReLU_backward):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    \n",
    "\n",
    "    A = np.maximum(0, Z)\n",
    "\n",
    "    assert (A.shape == Z.shape)\n",
    "\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def sigmoid(Z):\n",
    "  \n",
    "    # A = 1 / (1 + np.exp(-Z))\n",
    "    Z = np.clip(Z, -709, 36)\n",
    "    A = expit(Z)\n",
    "    if np.max(A) == 1:\n",
    "        print('whats the fuck')\n",
    "    cache = Z\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    # e_x = np.exp(Z - np.max(Z))\n",
    "    # A = e_x / e_x.sum()\n",
    "    Z = np.clip(Z, -709, 709)\n",
    "    T = np.exp(Z)\n",
    "    A = T / np.sum(T, axis=0)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def softmax_backward(dA, cache):\n",
    "    dZ = dA\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "   \n",
    "\n",
    "    Z = cache[0]\n",
    "    dZ = np.array(dA, copy=True)  # just converting dz to a correct object.\n",
    "\n",
    "    # When z <= 0, you should set dz to 0 as well.\n",
    "    dZ[Z <= 0] = 0\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "\n",
    "    Z = cache\n",
    "\n",
    "    # s = 1 / (1 + np.exp(-Z))\n",
    "    s = expit(Z)\n",
    "    dZ = dA * s * (1 - s)\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)  # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "        assert (parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert (parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def initialize_parameters_he(layers_dims):\n",
    "\n",
    "    parameters = {}\n",
    "    L = len(layers_dims) - 1  # integer representing the number of layers\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l - 1]) * np.sqrt(\n",
    "            2.0 / layers_dims[l - 1])\n",
    "        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and Backward Propagation:#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://qph.fs.quoracdn.net/main-qimg-e599270915026aeb9b5e47cb95e8097c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Propagation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    assert (Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "\n",
    "    return Z, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation, keep_prob=1.0):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"softmax\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        D = np.random.rand(A.shape[0], A.shape[1])\n",
    "        D = D <= keep_prob\n",
    "        A = A * D\n",
    "        A = A / keep_prob\n",
    "        activation_cache = [activation_cache, D]\n",
    "\n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters, keep_prob=1.0):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2  # number of layers in the neural network\n",
    "\n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)],\n",
    "                                             activation=\"relu\", keep_prob=keep_prob)\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation=\"softmax\")\n",
    "    caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert (AL.shape[1] == X.shape[1])\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost Function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_softmax_with_reg(AL, parameters, lambd, Y):\n",
    "    m = Y.shape[1]\n",
    "    # Compute the L2 regularization.\n",
    "    L = len(parameters) // 2  # number of layers in the neural network\n",
    "    L2_regularization_cost = 0\n",
    "    for l in range(1, L):\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        L2_regularization_cost = L2_regularization_cost + np.sum(np.square(Wl))\n",
    "    L2_regularization_cost = (lambd / (2 * m)) * L2_regularization_cost\n",
    "    # Compute loss from aL and y.\n",
    "    cc1 = np.log(AL)\n",
    "    logprobs = np.multiply(cc1, Y)\n",
    "    cost = (-1 / m) * np.nansum(logprobs)\n",
    "    cost = cost + L2_regularization_cost\n",
    "    cost = np.squeeze(cost)  # To make sure the shape is what we expect\n",
    "    assert (cost.shape == ())\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward Propagation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache, lambd):\n",
    "    # here the cache is not the caches from forward, but caches[l][0], which is a tuple of (A_prev, W, b). where caches[l][1] is cached Z.\n",
    "    A_prev, W, b = cache\n",
    "\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1.0 / m) * np.dot(dZ, A_prev.T) + (lambd / m) * W\n",
    "    db = (1.0 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation, lambd, keep_prob=1.0):\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == \"relu\":\n",
    "        D = activation_cache[1]\n",
    "        dA = dA * D\n",
    "        dA = dA / keep_prob\n",
    "        dZ = relu_backward(dA=dA, cache=activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(cache=linear_cache, dZ=dZ, lambd=lambd)\n",
    "\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(cache=activation_cache, dA=dA)\n",
    "        dA_prev, dW, db = linear_backward(cache=linear_cache, dZ=dZ, lambd=lambd)\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(cache=activation_cache, dA=dA)\n",
    "        dA_prev, dW, db = linear_backward(cache=linear_cache, dZ=dZ, lambd=lambd)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward_softmax(AL, Y, caches, lambd, keep_prob=1.0):\n",
    "    grads = {}\n",
    "    L = len(caches)  # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)  # after this line, Y is the same shape as AL\n",
    "\n",
    "    # Initializing the backpropagation with softmax\n",
    "    dAL = AL - Y \n",
    "\n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L - 1]\n",
    "    grads[\"dA\" + str(L - 1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,\n",
    "                                                                                                      current_cache,\n",
    "                                                                                                      \"softmax\", lambd=lambd)\n",
    "\n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L - 1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)]\n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, \"relu\",\n",
    "                                                                    lambd=lambd, keep_prob=keep_prob)\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update Parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:,k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        mini_batch_X = shuffled_X[:,num_complete_minibatches * mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:,num_complete_minibatches * mini_batch_size:]\n",
    "        ### END CODE HERE ###\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "   \n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(L):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        v[\"dW\" + str(l+1)] = np.zeros_like(parameters[\"W\" + str(l+1)])\n",
    "        v[\"db\" + str(l+1)] = np.zeros_like(parameters[\"b\" + str(l+1)])\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "   \n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(L):\n",
    "        \n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        # compute velocities\n",
    "        v[\"dW\" + str(l+1)] = beta * v[\"dW\" + str(l + 1)] + (1 - beta) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l+1)] = beta * v[\"db\" + str(l + 1)] + (1 - beta) * grads['db' + str(l + 1)]\n",
    "        # update parameters\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v[\"db\" + str(l + 1)]\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction and accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((m,10))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters) \n",
    "    probas=probas.T\n",
    "    for i in range(m):\n",
    "        for s in range(10):\n",
    "            if(probas[i][s]>=0.5):\n",
    "                p[i][s]=1\n",
    "            else:\n",
    "                p[i][s]=0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X,Y):\n",
    "    predictions = predict(X,Y, parameters)\n",
    "    prec=0\n",
    "    succ=[]\n",
    "    for i in range(X.shape[1]):\n",
    "        if(np.allclose(predictions[i],Y.T[i])):    \n",
    "            succ.append(i)\n",
    "        prec+=np.product(predictions[i]==Y.T[i])\n",
    "    return(succ,prec*100/X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, keep_prob=1, num_iterations=1000, print_cost = True):\n",
    "\n",
    "\n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters_he(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            AL, caches = L_model_forward(minibatch_X, parameters, keep_prob)\n",
    "            \n",
    "            # Compute cost and add to the cost total\n",
    "            lambd = 0.01\n",
    "            cost_total += compute_cost_softmax_with_reg(AL, parameters, lambd, minibatch_Y)\n",
    "            # Backward propagation\n",
    "            grads = L_model_backward_softmax(AL, minibatch_Y, caches, lambd, keep_prob=1.0)\n",
    "            \n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost = cost_total / m\n",
    "        \n",
    "       \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and (i % 100 == 0 or i == num_iterations-1):\n",
    "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
    "        if print_cost and i > 100 and (i % 1 == 0 or i == num_iterations-1):\n",
    "            costs.append(cost)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show(block=True)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the number of layers and units of our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = [X_train.shape[0], 50, 10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.03015997055095931\n",
      "Cost after iteration 100: 0.006790812973140935\n",
      "Cost after iteration 200: 0.006118405660098052\n",
      "Cost after iteration 300: 0.005722417660431178\n",
      "Cost after iteration 400: 0.0054413208349313675\n",
      "Cost after iteration 500: 0.00521675097644642\n",
      "Cost after iteration 600: 0.005027033982097121\n",
      "Cost after iteration 700: 0.004856591737887394\n",
      "Cost after iteration 800: 0.004706450211969119\n",
      "Cost after iteration 900: 0.004573409167459717\n",
      "Cost after iteration 999: 0.004456169120098096\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:22:08.979780\n",
      "Training accuracy: 88.54333333333334 %\n",
      "Test accuracy: 85.15 %\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "begin_time = datetime.datetime.now()\n",
    "#parameters = L_layer_model(X_train, Y_train, layers_dims,print_cost = True)\n",
    "parameters = model(X_train,Y_train, layers_dims, beta = 0.9, optimizer = \"momentum\")\n",
    "print(datetime.datetime.now() - begin_time)\n",
    "print(\"Training accuracy:\",accuracy(X_train,Y_train)[1],\"%\")\n",
    "print(\"Test accuracy:\",accuracy(X_test,Y_test)[1],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_label(X,Y,index):\n",
    "    try:\n",
    "        Z=X.T[s]\n",
    "        img=np.array(Z)\n",
    "        plt.figure(figsize = (10,2))\n",
    "        img=img.reshape(28,28)\n",
    "        plt.imshow(img)\n",
    "        P=predict(X,Y, parameters)\n",
    "        lbl=labels[int(np.where(P[index]==1)[1])] \n",
    "        true_lbl=labels[int(Ytest_o[index])]\n",
    "        S=lbl,true_lbl\n",
    "    except:\n",
    "        S=(\"I didn't recognize the image\")\n",
    "    if(len(S)==2):\n",
    "        print(\"Prediction:\",lbl,\"\\nTrue label:\",true_lbl)\n",
    "    else:\n",
    "        print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Trouser \n",
      "True label: Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=np.random.randint(10000, size=1)\n",
    "S=plt_label(X_test,Y_test,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
